\documentclass[a4paper]{report}

\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\usepackage[spanish]{babel}

\begin{document}

\title{
  Universidad Nacional de La Plata\\Facultad de Inform\'atica\\
  \bigskip
  Especializaci\'on en C\'omputo de Altas Prestaciones\\
  \bigskip
  Herramientas para el Soporte de An\'alisis de Rendimiento
}

\author{
  Alumno: Andr\'es More - {\tt amore@hal.famaf.unc.edu.ar}\\
  Director: Dr Fernando G. Tinetti - {\tt fernando@lidi.info.unlp.edu.ar}
}

%\date{}

\maketitle

\begin{abstract}

  \bigskip

  Este documento describe una investigaci\'on realizada como trabajo final para
  la Especializaci\'on en C\'omputo de Altas Prestaciones dictada en la
  Facultad   de Inform\'atica de la Universidad Nacional de La Plata.
  El tema de investigaci\'on consiste en m\'etodos y herramientas para
  an\'alisis del comportamiento en aplicaciones de alto rendimiento.

  \bigskip

  Luego de la introducci\'on de terminolog\'ia y bases te\'oricas del
  an\'alisis cuantitativo de rendimiento, se resume la experiencia de utilizar
  herramientas para conocer donde se deber\'ia localizar los esfuerzos de
  optimizaci\'on. Antes de concluir se propone un modelo para este tipo de
  aplicaciones utilizando una abstracci\'on simplificada de etapas, cuya
  utilizaci\'on simplifica el an\'alisis de rendimiento y su optimizaci\'on.

\end{abstract}

\tableofcontents

\chapter{Introducci\'on}

Este cap\'itulo introduce este trabajo y su alcance. Luego de revisar la
motivaci\'on del mismo, se resume el estado actual de la investigaci\'on y se
detalla el contenido restante del informe.

\section{Motivaci\'on}

En el \'area de c\'omputo de altas prestaciones los desarrolladores son en su
mayor\'ia los especialistas del dominio del problema a investigar, sin tener
necesariamente conocimientos avanzados de programaci\'on y optimizaci\'on de
rendimiento. Este hecho resulta en menos tiempo para an\'alisis de resultados
e impacta directamente en la productividad de cualquier grupo de
investigaci\'on. Las rutinas m\'as demandantes de c\'alculo son en su
mayor\'ia cient\'ificas, y su complejidad s\'olo hace posible su correcta
implementaci\'on solo por especialistas en el dominio.

\bigskip

Con mayor impacto que en otras \'areas de la computaci\'on, el c\'odigo
optimizado puede ejecutarse \'ordenes de magnitud mejor que implementaciones
directas \cite{mm-matrixmultiplicationtool}. Adem\'as, se utiliza
programaci\'on en paralelo para obtener la mayor cantidad disponible de
capacidad de c\'omputo; aumentando la complejidad a\'un m\'as
\cite{parallel-programming}.

\bigskip

El proceso de optimizaci\'on de una implementaci\'on termina entonces siendo
hecho de modo artesanal, sin conocimiento de las herramientas disponibles y
sus capacidades, y sin mucha informaci\'on cuantitativa para dirigir los
esfuerzos de optimizaci\'on. Incluso se llega a preferir la implementaci\'on
{\em ad-hoc} de algoritmos en lugar de la utilizaci\'on de librer\'ias ya
disponibles, optimizadas profundamente y con correctitud comprobada por el
paso del tiempo.

\section{Alcance}

Este trabajo considera principalmente los ambientes mayormente utilizados en
el c\'omputo de aplicaciones de alto rendimiento. A trav\'es de las
estad\'isticas mostradas por el Top 500 ({\tt http://www.top500.org}), se
puede determinar que los sistemas de memoria distribu\'ida corriendo sobre
GNU/Linux son los m\'as uitlizados. Tambi\'en denominados sistemas Beowulf
\cite{beowulf}.

\section{Estado Actual}

Actualmente existe incontables herramientas para el an\'alisis de c\'odigo, la
mayor\'ia siendo propietarias o aplicando a un sistema, lenguaje a librer\'ia
en particular, o abstrayendo la ejecucion a diferentes niveles de
abstracci\'on.

\bigskip

Algunas herramientas funcionan a nivel de contadores de hardware (PTU, PAPI),
otras sobre n\'ucleo del sistema operativo (oprof, kprobes), otras
instrumentan el soporte en tiempo de ejecuci\'on sobre el cual corren los
programas, otras modifican el c\'odigo fuente para extraer datos y otras
simplemente miden la utilizaci\'on de los recursos disponibles en el sistema.

\section{Organizaci\'on del Contenido}

El resto del documento explica teor\'ia de an\'alisis de rendimiento y temas
relacionados. El cap\'itulo 2 discute el an\'alisis de rendimiento, sus
principios y teor\'ias. El cap\'itulo 3 detalla las herramientas m\'as
utilizadas. El cap\'itulo 4 ejemplifica la aplicaci\'on de una herramienta
para obtener informaci\'on de an\'alisis. El cap\'itulo 5 concluye y el
cap\'itulo 6 detalla posibles trabajos futuros.

\chapter{An\'alisis de Rendimiento}

Este cap\'itulo introduce el concepto de rendimiento y teor\'ia sobre el
an\'alisis de rendimiento.

\section{Definici\'on}

El rendimiento se caracteriza por la cantidad de trabajo de c\'omputo que se
logra en comparaci\'on con la cantidad de tiempo y el uso de los recursos.

\section{M\'etricas}

Algunos ejemplos de medida de rendimiento son:

\begin{enumerate}
\item el ancho de banda y la latencia m\'inima de un canal de comunicaci\'on,
  una jerarqu\'ia de memorias o unidades   de almacenamiento
\item la cantidad de instrucciones, operaciones, datos o trabajo a procesar
  por cierta unidad de tiempo
\item rendimiento por unidad de energ\'ia o por costo asociado
\end{enumerate}

Para medir el rendimiento se utilizan pruebas de referencias denominadas
{\em benchmarks}, estas pueden ser aplicaciones sint\'eticas constru\'idas
especialmente para ejercitar ciertos recursos computacionales o incluso
aplicaciones del mundo real ejecutadas sobre un mismo conjunto de datos para
facilitar la comparaci\'on de resultados.

\bigskip

Otro m\'etodo consiste en medir el uso de los recursos del sistema mientras se
ejercita el mismo con un trabajo dado. Por ejemplo: el nivel de carga, la
cantidad de operaciones realizadas por el sistema operativo o la unidad de
procesamiento.

\section{Benchmarks}

Las caracter\'isticas deseables son portabilidad, simplicidad, estabilidad y
reproducci\'on de resultados. Esto permite que sean utilizadas para realizar
mediciones cuantitativas y as\'i realizar comparaciones de optimizaciones o
entre sistemas de c\'omputo diferentes. Tambi\'en se pide que el tiempo de
ejecuci\'on sea razonable y que el tama\~no del problema sea ajustable para
poder seguir utilizandose con el paso del tiempo y el avance de las
tecnolog\'ias.

\bigskip

A continuaci\'on se introducen algunas de las m\'as utilizadas, junto con
detalles y ejemplos de sus reportes.

\subsection{STREAM}

STREAM \cite{stream} es un benchmark sint\'etico a trav\'es de un simple
programa que mide el ancho de banda de memoria sostenido en MB/s y el
rendimiento de computaci\'on relativa de algunos vectores simples de c\'alculo.
Se utiliza para dimensionar el ancho de banda de acceso de escritura o lectura
a la memoria principal del sistema bajo an\'alisis.

\begin{verbatim}
  STREAM version $Revision: 1.2 $
  -------------------------------------------------------------
  This system uses 8 bytes per DOUBLE PRECISION word.
  -------------------------------------------------------------
  Array size = 10000000, Offset = 0
  Total memory required = 228.9 MB.
  Each test is run 10 times, but only
  the *best* time for each is used.
  -------------------------------------------------------------
  Function     Rate (MB/s)   Avg time     Min time     Max time
  Copy:        4764.1905       0.0337       0.0336       0.0340
  Scale:       4760.2029       0.0338       0.0336       0.0340
  Add:         4993.8631       0.0488       0.0481       0.0503
  Triad:       5051.5778       0.0488       0.0475       0.0500
  -------------------------------------------------------------
  Solution Validates
\end{verbatim}

Dentro de una misma ejecuci\'on de este benchmark, se realizan diferentes
operaciones en memoria.

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{|l|l|l|}\hline
      {\bf Funci\'on} & {\bf Operaci\'on} & {\bf Descripci\'on} \\ \hline
      copy & $ \forall i $ $ b_{i} = a_{i} $ & copia simple \\ \hline
      scale & $ \forall i $ $ b_{i} = c \times a_{i} $ & multiplicaci\'on escalar \\ \hline
      add & $ \forall i $ $ c_{i} = b_{i} + a_{i} $ & suma directa \\ \hline
      triad & $ \forall i $ $ c_{i} = b_{i} + c \times a_{i} $ & suma y multiplicaci\'on escalar \\ \hline
    \end{tabular}
    \caption{Operaciones del Benchmark STREAM}
  \end{center}
  \label{stream}
\end{figure}

\subsection{Linpack}

Linpack \cite{linpack} es un conjunto de subrutinas {\it FORTRAN} que resuelven
problemas de algebra lineal como ecuaciones lineales y multiplicaci\'on de
matrices. HPL \cite{hpl} es una versi\'on portable del benchmark que incluye
el paquete Linpack pero utilizando sistemas de memoria distribu\'ida. El
paquete de software utiliza la librer\'ia MPI para comunicaci\'on entre los
 nodos de c\'omputo con memoria distribu\'ida.

\bigskip

TOP500.

\bigskip

Existe cierta controversia de que no es una buena forma de ejercitar un sistema
de computo distribuido ya que no implica uso importante de la red, solo
computo intensivo utilizando unidades aritmeticas y la jerarquia local de memoria.

\begin{verbatim}
============================================================
HPLinpack 2.0  --  High-Performance Linpack benchmark  --   September 10, 2008
Written by A. Petitet and R. Clint Whaley, Innovative Computing Laboratory, UTK
Modified by Piotr Luszczek, Innovative Computing Laboratory, UTK
Modified by Julien Langou, University of Colorado Denver
============================================================
An explanation of the input/output parameters follows:
T/V    : Wall time / encoded variant.
N      : The order of the coefficient matrix A.
NB     : The partitioning blocking factor.
P      : The number of process rows.
Q      : The number of process columns.
Time   : Time in seconds to solve the linear system.
Gflops : Rate of execution for solving the linear system.

The following parameter values will be used:
N      :   28888
NB     :     168
PMAP   : Row-major process mapping
P      :       4
Q      :       4
PFACT  :   Right
NBMIN  :       4
NDIV   :       2
RFACT  :   Crout
BCAST  :  1ringM
DEPTH  :       0
SWAP   : Mix (threshold = 64)
L1     : transposed form
U      : transposed form
EQUIL  : yes
ALIGN  : 8 double precision words
-------------------------------------------------------------------------------
- The matrix A is randomly generated for each test.
- The following scaled residual check will be computed:
||Ax-b||_oo / ( eps * ( || x ||_oo * || A ||_oo + || b ||_oo ) * N )
- The relative machine precision (eps) is taken to be 1.110223e-16
- Computational tests pass if scaled residuals are less than 16.0

Column=000168 Fraction=0.005 Mflops=133122.97
...
Column=025872 Fraction=0.895 Mflops=98107.60
=============================================================
T/V                N    NB     P     Q               Time                Gflops
-------------------------------------------------------------------------------
WR01C2R4       28888   168     4     4             165.83             9.693e+01
-------------------------------------------------------------------------------
||Ax-b||_oo/(eps*(||A||_oo*||x||_oo+||b||_oo)*N)=       0.0043035 ...... PASSED
============================================================
Finished      1 tests with the following results:
1 tests completed and passed residual checks,
0 tests completed and failed residual checks,
0 tests skipped because of illegal input values.
\end{verbatim}

\subsection{Intel MPI Benchmarks}

Es un conjunto de benchmarks cuyo objetivo es ejercitar y medir las funciones
m\'as importantes de MPI.

El benchmark m\'as conocido es el popular Ping Pong. Ejercita la transmisi\'on
de mensajes ida y vuelta entre dos nodos de c\'omputo con diferentes tama\~nos
de mensajes. Para obtener el m\'aximo ancho de banda posible, se ejercita la
comunicaci\'on con mensajes con datos grandes. Para obtener la m\'inima
latencia, se ejercita la comunicaci\'on con mensajes vac\'ios, sin datos.

\begin{verbatim}
# Intel (R) MPI Benchmark Suite V3.1, MPI-1 part
# Date                  : Wed Mar  3 10:45:16 2010
# Machine               : x86_64
# System                : Linux
# Release               : 2.6.16.46-0.12-smp
# Version               : #1 SMP Thu May 17 14:00:09 UTC 2007
# MPI Version           : 2.0
# MPI Thread Environment: MPI_THREAD_SINGLE
# Calling sequence was: ../IMB-MPI1 pingpong
# Minimum message length in bytes:   0
# Maximum message length in bytes:   4194304
#
# MPI_Datatype                   :   MPI_BYTE
# MPI_Datatype for reductions    :   MPI_FLOAT
# MPI_Op                         :   MPI_SUM
#
# List of Benchmarks to run:
# PingPong
#---------------------------------------------------
# Benchmarking PingPong
# #processes = 2
#---------------------------------------------------
#bytes #repetitions      t[usec]   Mbytes/sec
0         1000        17.13         0.00
1         1000        17.89         0.05
2         1000        17.82         0.11
4         1000        17.95         0.21
...
1048576           40      8993.23       111.19
2097152           20     17919.20       111.61
4194304           10     35766.45       111.84
\end{verbatim}

\subsubsection{HPCC}

El benchmark HPC Challenge (HPCC) es un conjunto de m\'ultiple micro
benchmarks utilizados frecuentemente para medir el rendimiento de un sistema
de c\'omputo. Entre ellos STREAM, HPL, Ping Pong, transformadas de
{\it Fourier} y otros.

La mejor m\'aquina depende de la aplicaci\'on a ejecutar, algunas aplicaciones
necesitan mejor ancho de banda de memoria, mejor canales de comunicaci\'on, o
la mayor capacidad de c\'omputo posible.

% TBD: insertar cuadro de localidad espacial y temporal

\begin{verbatim}
This is the DARPA/DOE HPC Challenge Benchmark version 1.2.0 October 2003
Produced by Jack Dongarra and Piotr Luszczek
Innovative Computing Laboratory
University of Tennessee Knoxville and Oak Ridge National Laboratory
See the source files for authors of specific codes.
Compiled on Dec 20 2007 at 12:54:49
Current time (1225739336) is Mon Nov  3 17:08:56 2008
Begin of Summary section.
\end{verbatim}

\begin{minipage}[b]{0.5\linewidth}
\begin{verbatim}
VersionMajor=1
VersionMinor=2
VersionMicro=0
VersionRelease=f
LANG=C
Success=1
sizeof_char=1
sizeof_short=2
sizeof_int=4
sizeof_long=8
sizeof_void_ptr=8
sizeof_size_t=8
sizeof_float=4
sizeof_double=8
sizeof_s64Int=8
sizeof_u64Int=8
sizeof_struct_double_double=16
CommWorldProcs=3
MPI_Wtick=1.000000e-06
HPL_Tflops=0.0674008
HPL_time=26.3165
HPL_eps=1.11022e-16
HPL_RnormI=9.6442e-11
HPL_Anorm1=3528.16
HPL_AnormI=3533.01
HPL_Xnorm1=12823.1
HPL_XnormI=4.66036
HPL_N=13856
HPL_NB=64
HPL_nprow=1
HPL_npcol=3
HPL_depth=2
HPL_nbdiv=2
HPL_nbmin=8
HPL_cpfact=C
HPL_crfact=R
HPL_ctop=1
HPL_order=R
HPL_dMACH_EPS=1.110223e-16
HPL_dMACH_SFMIN=2.225074e-308
HPL_dMACH_BASE=2.000000e+00
HPL_dMACH_PREC=2.220446e-16
HPL_dMACH_MLEN=5.300000e+01
HPL_dMACH_RND=1.000000e+00
HPL_dMACH_EMIN=-1.021000e+03
HPL_dMACH_RMIN=2.225074e-308
HPL_dMACH_EMAX=1.024000e+03
HPL_dMACH_RMAX=1.797693e+308
HPL_sMACH_EPS=5.960464e-08
HPL_sMACH_SFMIN=1.175494e-38
HPL_sMACH_BASE=2.000000e+00
HPL_sMACH_PREC=1.192093e-07
HPL_sMACH_MLEN=2.400000e+01
HPL_sMACH_RND=1.000000e+00
HPL_sMACH_EMIN=-1.250000e+02
HPL_sMACH_RMIN=1.175494e-38
HPL_sMACH_EMAX=1.280000e+02
HPL_sMACH_RMAX=3.402823e+38
dweps=1.110223e-16
sweps=5.960464e-08
HPLMaxProcs=3
HPLMinProcs=3
DGEMM_N=4618
StarDGEMM_Gflops=68.9053
SingleDGEMM_Gflops=70.2692
PTRANS_GBs=0.794254
PTRANS_time=0.479293
\end{verbatim}
\end{minipage}
\hspace{0.5cm}
\begin{minipage}[b]{0.5\linewidth}
\begin{verbatim}
PTRANS_residual=0
PTRANS_n=6928
PTRANS_nb=64
PTRANS_nprow=1
PTRANS_npcol=3
MPIRandomAccess_N=134217728
MPIRandomAccess_time=30.4475
MPIRandomAccess_CheckTime=14.0705
MPIRandomAccess_Errors=0
MPIRandomAccess_ErrorsFraction=0
MPIRandomAccess_ExeUpdates=536870912
MPIRandomAccess_GUPs=0.0176327
MPIRandomAccess_TimeBound=-1
MPIRandomAccess_Algorithm=0
RandomAccess_N=33554432
StarRandomAccess_GUPs=0.0186362
SingleRandomAccess_GUPs=0.0184568
STREAM_VectorSize=21332081
STREAM_Threads=8
StarSTREAM_Copy=4.34705
StarSTREAM_Scale=3.24366
StarSTREAM_Add=3.41196
StarSTREAM_Triad=3.46198
SingleSTREAM_Copy=4.53628
SingleSTREAM_Scale=3.38984
SingleSTREAM_Add=3.59073
SingleSTREAM_Triad=3.65083
FFT_N=8388608
StarFFT_Gflops=2.17339
SingleFFT_Gflops=2.26806
MPIFFT_N=8388608
MPIFFT_Gflops=1.7043
MPIFFT_maxErr=1.77722e-15
MPIFFT_Procs=2
MaxPingPongLatency_usec=5.37932
RandomlyOrderedRingLatency_usec=5.70686
MinPingPongBandwidth_GBytes=0.675574
NaturallyOrderedRingBandwidth_GBytes=0.531278
RandomlyOrderedRingBandwidth_GBytes=0.529161
MinPingPongLatency_usec=5.24521
AvgPingPongLatency_usec=5.30978
MaxPingPongBandwidth_GBytes=0.682139
AvgPingPongBandwidth_GBytes=0.678212
NaturallyOrderedRingLatency_usec=5.79357
FFTEnblk=16
FFTEnp=8
FFTEl2size=1048576
M_OPENMP=200505
omp_get_num_threads=8
omp_get_max_threads=8
omp_get_num_procs=8
MemProc=-1
MemSpec=-1
MemVal=-1
MPIFFT_time0=2.14577e-06
MPIFFT_time1=0.135205
MPIFFT_time2=0.0328519
MPIFFT_time3=0.0831249
MPIFFT_time4=0.137934
MPIFFT_time5=0.126668
MPIFFT_time6=9.53674e-07
CPS_HPCC_FFT_235=0
CPS_HPCC_FFTW_ESTIMATE=0
CPS_HPCC_MEMALLCTR=0
CPS_RA_SANDIA_NOPT=0
CPS_RA_SANDIA_OPT2=0
CPS_USING_FFTW=0
\end{verbatim}
\end{minipage}

\begin{verbatim}
End of Summary section.
End of HPC Challenge tests.
Current time (1225739478) is Mon Nov  3 17:11:18 2008
\end{verbatim}

\subsubsection{DEISA}

Un conjunto de aplicaciones de astrof\'isica, din\'amica de fluidos, modelado
clim\'atico, bio-ciencia, ciencia de los materiales, fusi\'on de energ\'ia y
f\'isica de particulas. Permite una medici\'on m\'as cercana al mundo real,
sin utilizar aplicaciones sint\'eticas. DEISA es de libre acceso pero no puede
ser redistribu\'ida por terceros.

\bigskip

$ t = N * C / f $

\section{T\'ecnicas}

An\'alisis de calidad de acuerdo a la ingenier\'ia del software.

\bigskip

El procedimiento usualmente consiste en ciclos de medir, localizar, optimizar,
comparar. Es muy importante mantener la disciplina en realizar un cambio a la
vez ya que esto asegura resultados reproducibles.

Los resultados deben tambi\'en ser correctamente guardados para evitar
problemas de datos. Si la configuraci\'on del sistema es din\'amica, conviene
realizar todas las pruebas de comparaci\'on durante una misma ejecuci\'on para
evitar diferencias debido a configuraci\'on o a actualizaci\'on de componentes.

\bigskip

La reproducci\'on de resultados es compleja, en el caso de no tener una
configuraci\'on de sistema estable en el tiempo, es recomendable siempre
ejecutar una versi\'on optimizada contra una version de referencia en un mismo
sistema de c\'omputo.

\bigskip

Los problemas a identificar inicialmente pueden ser: cuellos de botella,
overhead, problemas de balanceo, contenci\'on o mal uso de recursos
computacionales.

\section{Modelos}

paralelizacion. niveles. bit/instruccion/datos/tareas.

calculo de mejora. teorica versus real. 

Existen algunas leyes frecuentemente utilizadas durante el an\'alisis de
rendimiento. La ley de {\it Amdahl} \cite{amdahl} dimensiona la mejora que
puede obtenerse en un sistema de acuerdo a las mejoras logradas en sus
componentes.

\bigskip

Desde un punto de vista m\'as general, la ley de {\it Gustafson}
\cite{gustafson} establece que las aplicaciones que manejan problemas
repetitivos con conjuntos de datos similares pueden ser f\'acilmente
paralelizadas. En comparaci\'on, la ley anterior no escala el tama\~no o
resoluci\'on de problema cuando se incrementa la potencia de c\'alculo, es
decir con un tama\~no de problema fijo.

\bigskip

Para medir el grado de paralelismo de una aplicaci\'on puede utilizarse la
m\'etrica de Karp-Flatt \cite{karp-flatt}.

pipeline. formulas. rangos de optimizacion posibles.

simulacion.

\chapter{Herramientas}

Este cap\'itulo revisa.

\section{Taxonom\'ia}

din\'amico versus est\'atico.
tiempo de compilaci\'on versus tiempo de ejecuci\'on.

\section{gprof}

profiling din\'amico.

se necesita compilar la aplicaci\'on con una opci\'on espec\'ifica.

se necesita ejecutar la aplicaci\'on con un conjunto de datos dado.

datos del perfil de una aplicaci\'on.

se necesita ejecutar un analizador sobre los datos acumulados.

perfil plano. una lista de las funciones ejecutadas ordenadas por la cantidad
acumulada de tiempo utilizado.

el gr\'afico de llamadas. muestra el tiempo utilizado por las funciones y sus
hijos.

las funciones recursivas son manejadas de manera especial.

\subsection{perfil de ejecuci\'on}

time, cumulative seconds, self seconds, calls, self ms/call, total ms/call,
name

\subsection{gr\'afico de llamadas}

index, \% time, self, children, called, name

\subsection{comportamiento}

precisi\'on estad\'istica. muestreo. incompatibilidades.

\subsection{ejemplos}

\section{oprofile}

\subsection{introduccion}

historia. resumen. caracter\'isticas. 

\subsection{procedimiento}

ejecutar el profiler. ejecutar la aplicaci\'on. generar el resumen.

No se necesita el c\'odigo. C\'odigo anotado si hay s\'imbolos de depuracion o
{\it debugging}.

componentes del sistema.

contadores de performance.

costo adicional. overhead.

\subsection{Contadores de rendimiento}

Los registros de hardware implementando contadores m\'as utilizados son los
siguientes:

\begin{enumerate}
\item total processor cycles
\item total instructions
\item cycles stalled waiting for memory accesses
\item floating point divide instructions
\item L1 cache misses
\item floating point instructions
\item load instructions
\item store instructions
\end{enumerate}

\subsection{ejemplos}

\chapter{Casos de Estudio}

Este cap\'itulo aplica.

\section{Multiplicaci\'on de Matrices}

La multiplicaci\'on de matrices es una operaci\'on fundamental en m\'ultiples
campos de aplicaci\'on cient\'ifica como la resoluci\'on de ecuaciones
lineales y la representaci\'on de grafos y espacios dimensionales. Por ello
existe abundante material sobre el tema.

\bigskip

El c\'odigo fuente de una implementaci\'on simplista se encuentra adjuntado en
el ap\'endice. Al aplicar las herramientas vistas previamente se identifica
claramente que la multiplicaci\'on de los elementos de la matriz consume el
mayor tiempo de c\'omputo.

\bigskip

A continuaci\'on se muestra una comparaci\'on de diferentes m\'etodos, se
demuestra claramente con este ejercicio la sofisticaci\'on de librer\'ias
contra m\'etodos artesanales de optimizaci\'on.

\section{Distribuci\'on de Calor en Dos Dimensiones}

\section{Reinas}

\section{Transformadas de {\it Fourier}}

El c\'odigo fuente de una implementaci\'on simplista se encuentra adjuntado en
el ap\'endice. Al aplicar las herramientas vistas previamente se identifica
claramente que la evaluacion de derivadas parciales consume el mayor tiempo de
c\'omputo.

\bigskip

A continuaci\'on se muestra una comparaci\'on de diferentes m\'etodos, se
demuestra claramente con este ejercicio la sofisticaci\'on de librer\'ias
contra m\'etodos artesanales de optimizaci\'on.

\chapter{Conclusiones}

Este cap\'itulo concluye.

Aportes: un m\'etodo, el an\'alisis de diferentes herramientas. resumen
introductorio del tema. ejercicios que demuestran que la optimizaci\'on
artesanal no es buena.

\chapter{Trabajo Futuro}

Este cap\'itulo propone.

Una librer\'ia m\'as infrastructura para soporte de an\'alisis de modo
autom\'atico. Generaci\'on de reporte de rendimiento autom\'atico para guiar
optimizaciones. An\'alisis de mejora posible seg\'un formulas aplicadas a
etapas.

\begin{thebibliography}{9}

\bibitem{mm-matrixmultiplicationtool}
  A. More,
  \emph{A Case Study on High Performance Matrix Multiplication},
  {\tt http://code.google.com/p/mm-matrixmultiplicationtool},
  2008.

\bibitem{beowulf}
  T. Sterling, D. Savarese, D. J. Becker, J. E. Dorband, U. A. Ranawake,
  and C. V. Packer,
  \emph{Beowulf: A parallel workstation for scientific computation},
  1995.

\bibitem{mpi}
  Message Passing Interface Forum,
  \emph{MPI: A Message-Passing Interface Standard},
  2.2,
  2009.

\bibitem{openmp}
  OpenMP Architecture Review Board,
  \emph{OpenMP Application Program Interface}.
  3.0,
  2008.

\bibitem{tinetti}
  Fernando G Tinetti,
  \emph{C\'omputo Paralelo en Redes Locales de Computadoras},
  2004.

\bibitem{gprof}
  Susan L. Graham,  Peter B. Kessler,  Marshall K. McKusick,
  \emph{gprof: A Call Graph Execution Profiler},
  1982.
  
\bibitem{oprofile}
  J. Levon,
  \emph{oprofile: hardware profiler for Linux systems},
       {\tt http://oprofile.sourceforge.net}.
  
\bibitem{hennessy-patterson}
  John. L. Hennesy, David A. Patterson,
  \emph{Computer Architecture: A Quantitative Approach, 3rd Edition},
  2002.

\bibitem{intel}
  Intel Press,
  \emph{Intel64 and IA-32 Architectures Software Developer's Manual - Volume
    3B: System Programming Guide, Part 2},
  March 2010.

\bibitem{what}
  Ulrich Deeper,
  \emph{What Every Programmer Should Know About Memory},
  November 2007.

\bibitem{patterns}
  G. Mattson, B.A. Sanders and B.L. Massingill, 
  \emph{Patterns for Parallel Programming, Addison-Wesley},
  2004.
  
\bibitem{automatic-performance-analysis}
  T. Margalef, J. Jorba, O. Morajko, A. Morajko, E. Luque,
  \emph{Different approaches to automatic performance analysis of distributed
    applications},
  2004.
  
\bibitem{capturing-performance-knowledge}
  K. Huck, O. Hernandez, V. Bui, S. Chandrasekaran, B. Chapman, A. Malony,
  L McInnes, B. Norris,
  \emph{Capturing performance knowledge for automated analysis},
  2008.
  
\bibitem{automatic-openmp-mpi-analysis}
  F. Wolf, B. Mohr,
  \emph{Automatic performance analysis of hybrid MPI/OpenMP applications},
  2003.
  
\bibitem{intro-software-performance}
  C. Smith,
  \emph{Introduction to software performance engineering: origins and
    outstanding problems},
  2007.

\bibitem{future-software-performance}
  M. Woodside, G. Franks, D. Petriu,
  \emph{The Future of Software Performance Engineering},
  2007.

\bibitem{critical-overview}
  J. Browne,
  \emph{A critical overview of computer performance evaluation},
  1976.

\bibitem{hpctoolkit}
  Rice University,
  \emph{HPC Toolkit}, {\tt http://hpctoolkit.org}.
       
\bibitem{papi}
  University of Tennessee,
  \emph{Performance Application Programming Interface},
       {\tt http://icl.cs.utk.edu/papi}.
       
\bibitem{amdahl}
  G. M. Amdahl,
  \emph{Validity of single-processor approach to achieving large-scale
    computing capability},
  Proceedings of AFIPS Conference, Reston, VA. 1967. pp. 483-485.
  
\bibitem{twelve-ways}
  D. Bailey, \emph{Twelve Ways to Fool the Masses When Giving Performance
    Results on Parallel Computers},
  RNR Technical Report, RNR-90-020, NASA Ames Research Center, 1991.
  
\bibitem{gustafson}
  J. L. Gustafson,
  \emph{Reevaluating Amdahl's Law}, CACM, 31(5), 1988. pp. 532-533.
  
\bibitem{karp-flatt}
  A. H. Karp and H. P. Flatt,
  \emph{Measuring Parallel Processor Performance},
  Communication of the ACM Volume 33 Number 5, May 1990.
  
\bibitem{myth}
  {Lee, Victor W. and Kim, Changkyu and Chhugani, Jatin and Deisher, Michael
    and Kim, Daehyun and Nguyen, Anthony D. and Satish, Nadathur and
    Smelyanskiy, Mikhail and Chennupaty}, Srinivas, and Hammarlund, Per and
  Singhal, Ronak and Dubey, Pradeep,
  \emph{Debunking the 100X GPU vs. CPU myth: an evaluation of throughput
    computing on CPU and GPU},
  2010.
  
\bibitem{stream}
  John D. McCalpin,
  \emph{A Survey of Memory Bandwidth and Machine Balance in Current High
    Performance Computers},
  1995.
  
\bibitem{counters}
  Dong H. Ahn and Jeffrey S. Vetter,
  \emph{Scalable Analysis Techniques for Microprocessor Performance Counter
    Metrics},
  2002.
  
\bibitem{linpack}
  J. Dongarra, J. Bunch, C. Moler and G. W. Stewart, 
  \emph{LINPACK Users Guide},
  1979.
  
\bibitem{hpl}
  A. Petitet, R. C. Whaley, J. Dongarra and A. Cleary, 
  \emph{HPL - A Portable Implementation of the High-Performance Linpack
    Benchmark for Distributed-Memory Computers}, {\tt http://www.netlib.org/benchmark/hpl}
  2008.
  
\bibitem{parallel-programming}
  Paul E. McKenney,
  \emph{Is Parallel Programming Hard, And, If So, What Can You Do About It?},
  January, 2011.

\end{thebibliography}

\end{document}
