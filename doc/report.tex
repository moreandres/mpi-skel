\documentclass[a4paper]{report}

\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\usepackage[spanish]{babel}

\begin{document}

\title{
  Universidad Nacional de La Plata\\Facultad de Inform\'atica\\
  \bigskip
  Especializaci\'on en C\'omputo de Altas Prestaciones\\
  \bigskip
  Herramientas para el Soporte de An\'alisis de Rendimiento
}

\author{
  Alumno: Andr\'es More - {\tt amore@hal.famaf.unc.edu.ar}\\
  Director: Fernando Tinetti - {\tt fernando@lidi.info.unlp.edu.ar}
}

\date{Abril 2011}

\maketitle

\begin{abstract}

  Este documento describe una investigaci\'on realizada como trabajo final para
  la Especializaci\'on en C\'omputo de Altas Prestaciones dictada en la Facultad
  de Inform\'atica de la Universidad Nacional de La Plata.

  \bigskip

  El tema de investigaci\'on consiste en m\'etodos y herramientas para el soporte
  de an\'alisis de rendimiento en aplicaciones de alto rendimiento.

  \bigskip

  Luego de la introducion de terminologia y bases teoricas del analisis cuantitativo
  de rendimiento, se discute un modelo en particular de aplicacion en etapas.

  \bigskip

  Se resume la experiencia de utilizar las herramientas {\it gprof} y {\it oprofile}
  para localizar los puntos de las aplicaciones donde se deber\'ia localizar los
  esfuerzos de optimizaci\'on.

\end{abstract}

\tableofcontents

\chapter{Introducci\'on}

Este cap\'itulo introduce este trabajo. Luego de revisar la motivaci\'on del mismo,
se resume el estado actual de la investigaci\'on y se detalla el contenido restante
del informe.

\section{Motivaci\'on}

Los desarrolladores son especialistas del dominio.

\bigskip

Menos tiempo para resultados y publicaciones.

\bigskip

Optimizaci\'on artesanal.

\section{Estado Actual}

Herramientas propietarias.

\bigskip

Patrones de dise\~no.

\bigskip

Soporte en lenguajes.

\section{Organizaci\'on del Contenido}

El resto del documento explica teor\'ia de an\'alisis de rendimiento y temas
relacionados.

\chapter{An\'alisis de Rendimiento}

Este cap\'itulo describe.

\section{Definici\'on}

El rendimiento se caracteriza por la cantidad de trabajo de computo que se logra
en comparacion con la cantidad de tiempo y el uso de los recursos.

\section{M\'etricas}

instrucciones por segundo. FLOPs. rendimiento por WATT. por d\'olar.
latencia de interrupciones. 

Benchmarks, punto de referencia. aplicaci\'on sint\'etica vs aplicaciones del mundo
real. nucleos de computo. utilizada para realizar mediciones cuantitativas y
comparaciones de optimizaciones.

Buenas caracteristicas de un benchmark. estabilidad. reproduccion. tiempo de
ejecucion. ajuste de tama\~no del problema.

\subsubsection{STREAM}

ancho de banda de acceso de escritura o lectura a la memoria principal.

\subsubsection{HPL}

multiplicacion de matrices.

\subsubsection{HPCC}

conjunto de m\'ultiple micro benchmarks.
STREAM, HPL, ancho de banda y latencia, transformadas de {\it fourier}.

\subsubsection{DEISA}

un conjunto de aplicaciones de astrofisica, dinamica de fluidos, modelado climatico,
bio-ciencia, ciencia de los materiales, fusion de energia y fisica de particulas.

\bigskip

$ t = N * C / f $

\section{T\'ecnicas}

analisis de calidad de acuerdo a la ingenier\'ia del software.

\bigskip

el procedimiento usualmente consiste en medir, localizar, optimizar, comparar.
disciplina en un cambio a la vez asegura resultados reproducibles.

\bigskip

la reproduccion de resultados es compleja, en el caso de no tener una configuracion
de sistema estable en el tiempo, es recomendable siempre ejecutar una version
optimizada contra una version de referencia en un sistema de computo.

\bigskip

cuellos de botella. overhead. problemas de balanceo, contencion o uso de recursos.

\section{Modelos}

paralelizacion. niveles. bit/instruccion/datos/tareas.

calculo de mejora. teorica versus real. leyes de amdalah \cite{amdahl}, gustafson
\cite{gustafson} y karp-flatt \cite{karp-flatt}.

pipeline. formulas. rangos de optimizacion posibles.

\chapter{Herramientas}

Este cap\'itulo revisa.

\section{Taxonom\'ia}

din\'amico versus est\'atico.
tiempo de compilaci\'on versus tiempo de ejecucion.

\section{gprof}

profiling din\'amico.

se necesita compilar la aplicaci\'on con una opci\'on espec\'ifica.

se necesita ejecutar la aplicaci\'on con un conjunto de datos dado.

datos del perfil de una aplicaci\'on.

se necesita ejecutar un analizador sobre los datos acumulados.

perfil plano. una lista de las funciones ejecutadas ordenadas por la cantidad
acumulada de tiempo utilizado.

el gr\'afico de llamadas. muestra el tiempo utilizado por las funciones y sus hijos.

las funciones recursivas son manejadas de manera especial.

\subsection{perfil de ejecuci\'on}

time, cumulative seconds, self seconds, calls, self ms/call, total ms/call, name

\subsection{gr\'afico de llamadas}

index, \% time, self, children, called, name

\subsection{comportamiento}

precisi\'on estad\'istica. muestreo. incompatibilidades.

\subsection{ejemplos}

\section{oprofile}

\subsection{introduccion}

historia. resumen. caracter\'isticas. 

\subsection{procedimiento}

ejecutar el profiler. ejecutar la aplicaci\'on. generar el resumen.

no se necesita el c\'odigo.

c\'odigo anotado si hay s\'imbolos.

componentes del sistema.

contadores de performance.

costo adicional. overhead.

\subsection{contadores de rendimiento}

\subsection{ejemplos}

\chapter{Casos de Estudio}

Este cap\'itulo aplica.

\section{Multiplicaci\'on de Matrices}

La multiplicaci\'on de matrices es una operaci\'on fundamental en m\'ultiples campos
de aplicaci\'on cient\'ifica como la resoluci\'on de ecuaciones lineales y la
representaci\'on de grafos y espacios dimensionales. Por ello existe abundante
 material sobre el tema.

\bigskip

El c\'odigo fuente de una implementaci\'on simplista se encuentra adjuntado en el
ap\'endice. Al aplicar las herramientas vistas previamente se identifica claramente
que la multiplicaci\'on de los elementos de la matriz consume el mayor tiempo de
c\'omputo.

\bigskip

A continuaci\'on se muestra una comparaci\'on de diferentes m\'etodos, se demuestra
claramente con este ejercicio la sofisticaci\'on de librer\'ias contra m\'etodos
artesanales de optimizaci\'on.

\section{Distribuci\'on de Calor en Dos Dimensiones}

\section{Reinas}

\section{Transformadas de {\it Fourier}}

El c\'odigo fuente de una implementaci\'on simplista se encuentra adjuntado en el
ap\'endice. Al aplicar las herramientas vistas previamente se identifica claramente
que la evaluacion de derivadas parciales consume el mayor tiempo de c\'omputo.

\bigskip

A continuaci\'on se muestra una comparaci\'on de diferentes m\'etodos, se demuestra
claramente con este ejercicio la sofisticaci\'on de librer\'ias contra m\'etodos
artesanales de optimizaci\'on.

\chapter{Conclusiones}

Este cap\'itulo concluye.

Aportes: un m'\etodo, el an\'alisis de diferentes herramientas. resumen
introductorio del tema. ejercicios que demuestran que la optimizaci\'on artesanal
no es buena.

\chapter{Trabajo Futuro}

Este cap\'itulo propone.

una librer\'ia m\'as infrastructura para soporte de an\'alisis.
generaci\'on de reporte de rendimiento autom\'atico para guiar optimizaciones.
an\'alisis de mejora posible seg\'un formulas aplicadas a etapas.

\begin{thebibliography}{9}
  
\bibitem{mpi}
  Message Passing Interface Forum,
  \emph{MPI: A Message-Passing Interface Standard},
  2.2,
  2009.

\bibitem{openmp}
  OpenMP Architecture Review Board,
  \emph{OpenMP Application Program Interface}.
  3.0,
  2008.

\bibitem{tinetti}
  Fernando G Tinetti,
  \emph{C\'omputo Paralelo en Redes Locales de Computadoras},
  2004.

\bibitem{gprof}
 Susan L. Graham,  Peter B. Kessler,  Marshall K. McKusick,
 \emph{gprof: A Call Graph Execution Profiler},
 1982.

\bibitem{oprofile}
J. Levon,
\emph{oprofile: hardware profiler for Linux systems},
{\tt http://oprofile.sourceforge.net}.

\bibitem{hennessy-patterson}
 John. L. Hennesy, David A. Patterson,
 \emph{Computer Architecture: A Quantitative Approach, 3rd Edition},
 2002.

\bibitem{intel}
 Intel Press,
 \emph{Intel64 and IA-32 Architectures Software Developer's Manual - Volume 3B: System Programming Guide, Part 2},
 March 2010.

\bibitem{what}
 Ulrich Deeper,
 \emph{What Every Programmer Should Know About Memory},
 November 2007.

\bibitem{patterns}
 G. Mattson, B.A. Sanders and B.L. Massingill, 
 \emph{Patterns for Parallel Programming, Addison-Wesley},
 2004.

\bibitem{automatic-performance-analysis}
 T. Margalef, J. Jorba, O. Morajko, A. Morajko, E. Luque,
 \emph{Different approaches to automatic performance analysis of distributed applications},
 2004.

\bibitem{capturing-performance-knowledge}
 K. Huck, O. Hernandez, V. Bui, S. Chandrasekaran, B. Chapman, A. Malony, L McInnes, B. Norris,
 \emph{Capturing performance knowledge for automated analysis},
 2008.

\bibitem{automatic-openmp-mpi-analysis}
 F. Wolf, B. Mohr,
 \emph{Automatic performance analysis of hybrid MPI/OpenMP applications},
 2003.

\bibitem{intro-software-performance}
 C. Smith,
 \emph{Introduction to software performance engineering: origins and outstanding problems},
 2007.

\bibitem{future-software-performance}
 M. Woodside, G. Franks, D. Petriu,
 \emph{The Future of Software Performance Engineering},
 2007.

\bibitem{critical-overview}
 J. Browne,
 \emph{A critical overview of computer performance evaluation},
 1976.

\bibitem{hpctoolkit}
  Rice University,
 \emph{HPC Toolkit},
 {\tt http://hpctoolkit.org}.

\bibitem{papi}
  University of Tennessee,
  \emph{Performance Application Programming Interface},
  {\tt http://icl.cs.utk.edu/papi}.

\bibitem{amdahl}
  G. M. Amdahl,
  \emph{Validity of single-processor approach to achieving large-scale computing
    capability},
  Proceedings of AFIPS Conference, Reston, VA. 1967. pp. 483-485.

\bibitem{twelve-ways}
  D. Bailey, \emph{Twelve Ways to Fool the Masses When Giving Performance Results
    on Parallel Computers},
  RNR Technical Report, RNR-90-020, NASA Ames Research Center, 1991.

\bibitem{gustafson}
  J. L. Gustafson,
  \emph{Reevaluating Amdahl's Law}, CACM, 31(5), 1988. pp. 532-533.

\bibitem{karp-flatt}
  A. H. Karp and H. P. Flatt,
  \emph{Measuring Parallel Processor Performance},
  Communication of the ACM Volume 33 Number 5, May 1990.

\end{thebibliography}

\end{document}
